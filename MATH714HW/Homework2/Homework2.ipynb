{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1c9151",
   "metadata": {},
   "source": [
    "#### MATH714 Homework 2\n",
    "##### Stephen Cornelius\n",
    "\n",
    "1. **Iterative Methods**\n",
    "   \n",
    "   (a) Consider the $2 \\times 2$ matrix\n",
    "   $$\n",
    "        A = \\begin{pmatrix}\n",
    "        1 & p \\\\\n",
    "        -p & 1\n",
    "        \\end{pmatrix}.\n",
    "   $$\n",
    "   Under what conditions will the Jacobi and Gauss-Seidel methods converge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf4624",
   "metadata": {},
   "source": [
    "**Solution to 1(a):**\n",
    "\n",
    "> TODO: Look over this and figure out what it means. I do not think it is entirely correct.\n",
    "\n",
    "For the matrix $A = \\begin{pmatrix} 1 & p \\\\ -p & 1 \\end{pmatrix}$, we need to analyze the convergence conditions for both iterative methods.\n",
    "\n",
    "**Jacobi Method:**\n",
    "The Jacobi iteration matrix is $T_J = -D^{-1}(L+U)$ where $D$ is the diagonal, $L$ is the lower triangular, and $U$ is the upper triangular part of $A$.\n",
    "\n",
    "For our matrix:\n",
    "- $D = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$\n",
    "- $L + U = \\begin{pmatrix} 0 & p \\\\ -p & 0 \\end{pmatrix}$\n",
    "\n",
    "Therefore: $T_J = -\\begin{pmatrix} 0 & p \\\\ -p & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & -p \\\\ p & 0 \\end{pmatrix}$\n",
    "\n",
    "The eigenvalues of $T_J$ are found from $\\det(T_J - \\lambda I) = 0$:\n",
    "$$\\det\\begin{pmatrix} -\\lambda & -p \\\\ p & -\\lambda \\end{pmatrix} = \\lambda^2 + p^2 = 0$$\n",
    "\n",
    "So $\\lambda = \\pm ip$, and $|\\lambda| = |p|$.\n",
    "\n",
    "**Jacobi converges if and only if $\\rho(T_J) < 1$, which means $|p| < 1$.**\n",
    "\n",
    "**Gauss-Seidel Method:**\n",
    "The Gauss-Seidel iteration matrix is $T_{GS} = -(D+L)^{-1}U$.\n",
    "\n",
    "For our matrix:\n",
    "- $D + L = \\begin{pmatrix} 1 & 0 \\\\ -p & 1 \\end{pmatrix}$\n",
    "- $U = \\begin{pmatrix} 0 & p \\\\ 0 & 0 \\end{pmatrix}$\n",
    "\n",
    "Therefore: $T_{GS} = -\\begin{pmatrix} 1 & 0 \\\\ p & 1 \\end{pmatrix}\\begin{pmatrix} 0 & p \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & -p \\\\ 0 & -p^2 \\end{pmatrix}$\n",
    "\n",
    "The eigenvalues are $\\lambda_1 = 0$ and $\\lambda_2 = -p^2$.\n",
    "\n",
    "**Gauss-Seidel converges if and only if $\\rho(T_{GS}) < 1$, which means $|p^2| < 1$, so $|p| < 1$.**\n",
    "\n",
    "**Conclusion:**\n",
    "Both the Jacobi and Gauss-Seidel methods converge for the given matrix if and only if $|p| < 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71b38c",
   "metadata": {},
   "source": [
    "(b) Consider the $n \\times n$ matrix\n",
    "    $$\n",
    "        C = \\begin{pmatrix}\n",
    "        3 & -1 \\\\\n",
    "        -1 & 3 & -1 \\\\\n",
    "           & -1 & 3 & -1 \\\\\n",
    "           &    & & \\ddots &  \\\\\n",
    "           & & & -1 & 3 & -1  \\\\\n",
    "           & & & & -1 & 3 \n",
    "        \\end{pmatrix}.\n",
    "    $$\n",
    "    Starting from $u_0 \\in \\mathbb{R}^n$, for which values of $\\omega \\in \\mathbb{R}$ does the iteration \n",
    "    $$ u_{k+1} = u_k + \\omega(b-Cu_k) $$\n",
    "    for $k = 0,1,2,\\dots$ converge to a solution of $Cu = b$? What iterative method from the lectures does this most closely resemble? How is it different?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb743a54",
   "metadata": {},
   "source": [
    "**Solution to 1(b):**\n",
    "\n",
    "We are tasked with finding the values of $\\omega \\in \\mathbb{R}^n$ such that $u_{k+1} = u_k + \\omega(b - Cu_k)$ converges. If we let $T = I - \\omega C$ we have $$ u_{k+1} = u_k + \\omega (b - Cu_k) = u_k + \\omega b - \\omega Cu_k = u_k(I - \\omega C) + \\omega b = Tu_k + \\omega b.$$ So then we need that the spectral radius of $T$ needs to be less than $1$. So we find $\\rho(T)$. From the article, we have that \n",
    "\n",
    "\n",
    "   - This is equivalent to all eigenvalues of $I - \\omega C$ having magnitude less than 1\n",
    "\n",
    "3. **Find eigenvalues of the tridiagonal matrix $C$:**\n",
    "   - For the $n \\times n$ tridiagonal matrix $C$ with diagonal entries 3 and off-diagonal entries -1\n",
    "   - Eigenvalues are: $\\lambda_j = 3 - 2\\cos\\left(\\frac{j\\pi}{n+1}\\right)$ for $j = 1, 2, \\ldots, n$\n",
    "   - Range: $\\lambda_{\\min} = 3 - 2\\cos\\left(\\frac{\\pi}{n+1}\\right) \\approx 1$ and $\\lambda_{\\max} = 3 - 2\\cos\\left(\\frac{n\\pi}{n+1}\\right) \\approx 5$\n",
    "\n",
    "4. **Determine convergence range for $\\omega$:**\n",
    "   - Eigenvalues of $T = I - \\omega C$ are $1 - \\omega\\lambda_j$\n",
    "   - Need $|1 - \\omega\\lambda_j| < 1$ for all $j$\n",
    "   - This gives us the range: $0 < \\omega < \\frac{2}{\\lambda_{\\max}}$\n",
    "\n",
    "5. **Method identification:**\n",
    "   - This most closely resembles the **Richardson iteration** or **gradient descent method**\n",
    "   - Difference from standard methods: uses a fixed relaxation parameter $\\omega$ rather than optimal step sizes\n",
    "\n",
    "**Key Points to Develop:**\n",
    "- The optimal $\\omega$ for fastest convergence\n",
    "- Comparison with Jacobi and Gauss-Seidel methods\n",
    "- Why this is different from steepest descent (fixed vs. optimal step size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060a6754",
   "metadata": {},
   "source": [
    "2. **Triangular domain revisited with conjugate gradient**\n",
    "   Question 4 of the first homework assignment looked at solving the Poisson equation\n",
    "   $$ \\nabla^2u = f$$\n",
    "   on the triangular domain $T$ with vertices $(0,0), (1,0),$ and $(s,\\frac{1}{2})$ where $s = \\frac{\\sqrt{3}}{2}$. Dirchlet boundary conditions $u = 0$ are applied on the boundary $\\partial T$. For $n \\in \\mathbb{N}$ and $h = \\frac{1}{n}$, the domain is descretized with points \n",
    "   $$ \\vec{x}_{i,j} = (h(i + \\frac{1}{2}j), hsj) $$\n",
    "   for $0 \\leq i \\leq n, 0 \\leq j \\leq n-i$. The points where $i = 0, j = 0,$ of $i + j = n$ are boundary points, and all others are interior. Let $u_{i,j}$ be the numberical approximation for $u(x_{i,j})$. The Laplacian is discretized with points\n",
    "   $$ \\nabla^2_6u_{i,j} = \\frac{2(-6 u_{i,j} + u_{i+1,j} + u_{i,j-1} + u_{i-1,j+1} +u_{i-1,j} + u_{i,j+1} + u_{i+1,j-1})}{3h^2}. $$\n",
    "   As in Homework 1, consider solving the equation $\\nabla^2u = f$ using the $f$ that creates the exact solution\n",
    "   $$ u^{\\text{ex}}(x,y) = \\left( (2y-\\sqrt{3})^2- 3(2x-1)^2 \\right) \\sin y. $$\n",
    "   The problem can be expressed as a linear system $Au = f$ where $u \\in \\mathbb{R}^N$ is the solution vector at the $N = (n-1)(n-2)/2$ interior grid points. Define an approximate $2$-norm as \n",
    "   $$ ||r||_2 = \\sqrt{\\frac{s}{2n^2} \\sum_{j=1}^{n-1} \\sum_{i=1}^{n-j-1} r_{i,j}^2} $$\n",
    "   for a vector $r$ describing a field on the grid.\n",
    "   \n",
    "   (a) For a range of grid sizes from $n=10$ up to at least $n=160$ measure the wall-clock time $T_n$ to solve the system using your code. By making a log--log plot of $T_n$ versus $n$, fit the timing data to $$T_n = a n^b,$$ and comment on the exponent $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0344ca2",
   "metadata": {},
   "source": [
    "(b) Write a code to implement the conjugate gradient (CG) algorithm to solve $Au=f$. Your code should not explicitly build $A$ as a dense matrix. It should either represent $A$ as a sparse matrix, or contain a function that can directly compute $Aq$ for a given vector $q$. The CG algorithm should terminate when $||r||_2 < 10^{-10}$, where $r$ is the residual vector. For the case when $n=40$ test that your program gives the same results as the original version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342177a8",
   "metadata": {},
   "source": [
    "(c) For $n=10,20,40,80,160$, calculate the number of iterations $k$ required in order to reach the termination criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b052ec",
   "metadata": {},
   "source": [
    "(d) Measure the wall-clock time of the CG algorithm to solve the linear system for a range of grid sizes from $n=10$ up to at least $n=160$. Fit the data to $T_n = an^b$ and comment on how the exponent compares to your result from part (a)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d06ed40",
   "metadata": {},
   "source": [
    "(e) Consider the block Jacobi preconditioner $M$ with block sizes of $w=\\lfloor \\sqrt{N} \\rfloor$. In general, $w$ will not evenly divide $N$, and therefore let the final block of $M$ be smaller. Implement the preconditioned CG algorithm, and repeat part (c) to measure the number of iterations required to reach the termination criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d55f5e",
   "metadata": {},
   "source": [
    "(f) Repeat part (d), fitting the timing data to $T_n = an^b$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628e5fef",
   "metadata": {},
   "source": [
    "3. **ODE integration methods**\n",
    "\n",
    "(a) Consider solving the differential equation $y' = f(t,y)$ at timepoints $t_k$ with corresponding numerical solutions $y_k$. The multi-satep Nystr&ouml;m numerical method is based upon the integral relation $$y(t_{k+1}) = y(t_{k-1}) + \\int_{t_{k-1}}^{t_{k+1}} f(t,y) dt.$$ \n",
    "\n",
    "Derive an implicit multi-step numerical method by approximating the integrand $f(t,y)$ with the polynomial interpolant using the function values at $t_{k-2}$, $t_{k-1}$, $t_k$, and $t_{k+1}$. Your method should have the form $$y_{k+1} = y_{k-1} + h(\\alpha f_{k-2}+\\beta f_{k-1} + \\gamma f_k+\\eta f_{k+1}) \\tag{1}$$ where $\\alpha$, $\\beta$, $\\gamma$, and $\\eta$ are constants to be determined, $h$ is the timestep interval size, and $f_l=f(t_l,y_l)$ for an arbitrary $l$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7747848",
   "metadata": {},
   "source": [
    "(b) Find the exact solution to the second-order differential equation $$ y''(t)+2y'(t) + 26y(t)=0, \\tag{2}$$ subject to the initial conditions $y(0)=1$, $y'(0)=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88951e4",
   "metadata": {},
   "source": [
    "(c) Write $y''(t)+2y'(t) + 26y(t)=0$ as a coupled system of two first-order differential equations for $\\vec{y} = (y,v) = (y,y')$. Solve the system over the interval $0 \\leq t \\leq 3$ with a timestep of $h = 0.02$ using your multi=step method from part (a).\n",
    "\n",
    "Before (1) can be applied, $\\vec{y}_1$ and $\\vec{y}_2$ must be calculated accurately. Use one of the following two approaches:\n",
    "\n",
    "    i. set them based on the exact solution from part (b).\n",
    "\n",
    "    ii. calculate them using the classical fourth-order Runge-Kutta method.\n",
    "    \n",
    "Plot the exact and numerical solutions over the range $0 \\leq t \\leq 3$.\n",
    "\n",
    "Make a log-log plot of the absolute error between the numerical and exact values of $y$ at $t = 3$ as a function of $h$, over the range from $h = 10^{-3}$ to $h = 10^{-1}$.\n",
    "\n",
    "Show that your method is fourth-order accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c38fcc",
   "metadata": {},
   "source": [
    "(d) Suppose that instead of setting $\\vec{y}_1$ and $\\vec{y}_2$ accurately, you instead make use of forward Euler steps. Create a log-log plot of the absolute error of $y$ at $t=3$ as a function of $h$. Determine the order of accuracy, and discuss why this is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93df72b5",
   "metadata": {},
   "source": [
    "4. **Linear Difference Equation** \n",
    "   \n",
    "   (a) Find the general solution of the linear difference equation $$U_{n+3} + 2U_{n+2} - 4U_{n+1} - 8U_n =0. \\tag{3} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3935aafd",
   "metadata": {},
   "source": [
    "(b) Determine the particular solution with initial data $U_0=4$, $U_1=-2$, and $U_2=8$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad8d461",
   "metadata": {},
   "source": [
    "(c) Consider the iteration $$\\left(\\begin{array}{c} U_{n+1} \\\\ U_{n+2} \\\\ U_{n+3} \\end{array} \\right)\n",
    "    =\n",
    "    \\left( \\begin{array}{ccc} 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 8 & 4 & -2 \\end{array} \\right)\n",
    "    \\left(\\begin{array}{c} U_{n} \\\\ U_{n+1} \\\\ U_{n+2} \\end{array} \\right),$$ which we can define as $\\mathbf{U}_{n+1} = A \\mathbf{U}_n$. The matrix $A$ is called the companion matrix for the difference equation in (3). A general solution of the difference equation is given by $\\mathbf{U}_{n} = A^n \\mathbf{U}_0$. If $A=RJR^{-1}$ is the Jordan canonical form for $A$, then $A^n = RJ^n R^{-1}$. Determine the eigenvalues and Jordan canonical form for this matrix and show how this is related to the general solution found in part (a)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
